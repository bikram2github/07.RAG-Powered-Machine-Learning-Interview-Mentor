# 07.RAG-Powered-Machine-Learning-Interview-Mentor
RAG-Powered Machine Learning Interview Mentor

# ğŸ¤– RAG-Powered Machine Learning Interview Mentor

An end-to-end AI web application that helps users prepare for Machine Learning interviews by providing accurate, context-aware answers using **Retrieval-Augmented Generation (RAG)** and Large Language Models (LLMs).

---

## ğŸš€ Project Overview

Preparing for ML interviews often requires searching through multiple resources. This project builds an **AI Interview Mentor** that allows users to upload PDFs (notes, books, resumes, guides) and ask questions. The system retrieves the most relevant content and generates precise answers using LLMs.

It combines:
- ğŸ” Semantic search over documents
- ğŸ§  LLM reasoning
- ğŸ’¬ Conversational, history-aware Q&A

---

## âœ¨ Key Features

- âœ… RAG-based question answering for ML topics  
- âœ… Upload and process PDF documents  
- âœ… Context-aware and history-aware responses  
- âœ… Semantic search using vector embeddings  
- âœ… Low-latency generation with **Groq LLM**  
- âœ… Interactive **Streamlit** web interface  
- âœ… End-to-end pipeline: PDF â†’ Chunks â†’ Vectors â†’ LLM Answer  

---

## ğŸ› ï¸ Tech Stack

**Programming:** Python  
**LLM & RAG:** LangChain, Groq (OpenAI API)  
**Embeddings:** Hugging Face  
**Vector Store:** FAISS  
**Web Framework:** Streamlit  
**Libraries:** PyPDF, NumPy, Pandas  
**Tools:** Git, GitHub  

---

ğŸ”„ How It Works

User uploads PDF files
Text is extracted and chunked
Embeddings are generated using Hugging Face models
Vectors stored in FAISS index
Relevant chunks retrieved for each query
Groq LLM generates accurate answers using retrieved context


