{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8978fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bikra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa48f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(api_key=\"Your own api key\", model=\"openai/gpt-oss-20b\", temperature=0)\n",
    "embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72b286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2425c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=PyPDFLoader(\"ML Guide.pdf\")\n",
    "page=doc.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ee8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts=text_splitter.split_documents(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f424ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorstore=FAISS.from_documents(texts, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b48e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever(kwargs={\"search_kwargs\":{\"k\":3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc1b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a helpful and precise AI assistant. \"\n",
    "    \"Answer the user's question strictly based on the provided context. \"\n",
    "    \"If the context does not contain enough information to answer, respond with: 'I don't know.' \"\n",
    "    \"Do not use any external or prior knowledge. \"\n",
    "    \"If the user makes grammar mistakes, fix them in your answer. \"\n",
    "    \"Keep your answer clear, concise, and directly relevant to the context below.\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    "    )\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"You are an AI assistant that helps provide context for user questions based on previous interactions. \"\n",
    "    \"Given the conversation history and a new user question, rephrase or expand the question to include relevant context from the history. \"\n",
    "    \"If the history does not provide additional context, return the original question.\\n\\n\"\n",
    "    )\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")],)\n",
    "\n",
    "question_contextualizer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "718922ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever=create_history_aware_retriever(llm,retriever,question_contextualizer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a1e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain=create_stuff_documents_chain(llm,qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e8d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= create_retrieval_chain(history_aware_retriever, qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0f8f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609e4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_message(chat_history, max_len=20):\n",
    "    \"\"\"Keep only the most recent N messages in chat history.\"\"\"\n",
    "    if len(chat_history)>max_len:\n",
    "        return chat_history[-max_len:]\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "094a2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    global chat_history\n",
    "    chat_history=trim_message(chat_history)\n",
    "    response=chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "    print(f\"Question={question}\")\n",
    "    print(f\"Answer={response['answer']}\\n\")\n",
    "    chat_history.extend([\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=response['answer'])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d00257cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question=what is supervised learning?\n",
      "Answer=Supervised learning is a type of machine learning where the model learns from labelled data. Each training example consists of input features paired with an expected output (label), and the algorithm learns to map inputs to outputs—examples include classification (e.g., spam detection) and regression (e.g., house‑price prediction).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"what is supervised learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47bc8a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question=can you give me an code example?\n",
      "Answer=Sure! Here’s a simple Python example that trains a decision‑tree classifier on the Iris dataset:\n",
      "\n",
      "```python\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "# Load data\n",
      "iris = load_iris()\n",
      "X, y = iris.data, iris.target\n",
      "\n",
      "# Split into training and test sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Train the model\n",
      "clf = DecisionTreeClassifier()\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "# Evaluate\n",
      "print(\"Test accuracy:\", clf.score(X_test, y_test))\n",
      "```\n",
      "\n",
      "This code demonstrates a typical supervised‑learning workflow: loading labelled data, splitting it, training a model, and evaluating its performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"can you give me an code example?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74a039e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question=Who is Virat Kohli?\n",
      "Answer=I don't know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"Who is Virat Kohli?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "337d2c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is supervised learning?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Supervised learning is a type of machine learning where the model learns from labelled data. Each training example consists of input features paired with an expected output (label), and the algorithm learns to map inputs to outputs—examples include classification (e.g., spam detection) and regression (e.g., house‑price prediction).', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='can you give me an code example?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Sure! Here’s a simple Python example that trains a decision‑tree classifier on the Iris dataset:\\n\\n```python\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n# Load data\\niris = load_iris()\\nX, y = iris.data, iris.target\\n\\n# Split into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Train the model\\nclf = DecisionTreeClassifier()\\nclf.fit(X_train, y_train)\\n\\n# Evaluate\\nprint(\"Test accuracy:\", clf.score(X_test, y_test))\\n```\\n\\nThis code demonstrates a typical supervised‑learning workflow: loading labelled data, splitting it, training a model, and evaluating its performance.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Who is Virat Kohli?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I don't know.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03d08740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: what is supervised learning?\n",
      "\n",
      "AI: Supervised learning is a type of machine learning where the model learns from labelled data. Each training example consists of input features paired with an expected output (label), and the algorithm learns to map inputs to outputs—examples include classification (e.g., spam detection) and regression (e.g., house‑price prediction).\n",
      "\n",
      "HUMAN: can you give me an code example?\n",
      "\n",
      "AI: Sure! Here’s a simple Python example that trains a decision‑tree classifier on the Iris dataset:\n",
      "\n",
      "```python\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "# Load data\n",
      "iris = load_iris()\n",
      "X, y = iris.data, iris.target\n",
      "\n",
      "# Split into training and test sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Train the model\n",
      "clf = DecisionTreeClassifier()\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "# Evaluate\n",
      "print(\"Test accuracy:\", clf.score(X_test, y_test))\n",
      "```\n",
      "\n",
      "This code demonstrates a typical supervised‑learning workflow: loading labelled data, splitting it, training a model, and evaluating its performance.\n",
      "\n",
      "HUMAN: Who is Virat Kohli?\n",
      "\n",
      "AI: I don't know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in chat_history:\n",
    "    print(f\"{str.upper(msg.type)}: {msg.content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
